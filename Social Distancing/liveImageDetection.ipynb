{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "#0 means reading internal camera\n",
    "\n",
    "ret, frame = webcam.read() #reading camera\n",
    "print(ret) #checking the status of camera\n",
    "webcam.release()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('my_face',frame)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    #capture frame by frame\n",
    "    \n",
    "    ret, frame = webcam.read()\n",
    "    \n",
    "    # our operations on the frame came here\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('face',gray)     #display resulting frames\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    elif cv2.waitKey(10) & 0xFF == ord('s'):\n",
    "        cv2.imwrite('f1.png', frame)\n",
    "        \n",
    "# release the camera when everything is done\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'distroyAllWindows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-357c88b410df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mwebcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'distroyAllWindows'"
     ]
    }
   ],
   "source": [
    "# haar cascade classifier - ml \n",
    "# face.xml - pretrained model in it\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "fontScale = 1\n",
    "\n",
    "facecascade = cv2.CascadeClassifier('face.xml')\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = webcam.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = facecascade.detectMultiScale(gray, scaleFactor = 1.2, minNeighbors = 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w, y+h),(0,255,0),2)\n",
    "        cv2.putText(frame, 'Mohit',(x,y), font, fontScale, (0,0,255),2)\n",
    "        cv2.imshow('Live detection',frame)\n",
    "    if cv2.waitKey(1) & 0xFf == ord('q'):\n",
    "        break\n",
    "        \n",
    "webcam.release()\n",
    "cv2.distroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a black image\n",
    "img = np.zeros((300,300,3), np.uint8)\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw line on the black image\n",
    "\n",
    "#(img, startParameter, stop, color, thickness)\n",
    "img1 = cv2.line(img, (0,0), (100,100), (255,0,0), 5)\n",
    "cv2.imshow('f1',img1)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw circle on the black image\n",
    "\n",
    "#(img, center, radius, color, thickness)\n",
    "img2 = cv2.circle(img, (150,130), 50, (0,255,0), 5 )\n",
    "cv2.imshow('f2', img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put text\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "fontScale = 1\n",
    "\n",
    "img3 = cv2.putText(img, 'Mohit',(200,50), font, fontScale, (255,0,0),5)\n",
    "cv2.imshow('f3', img3)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## social distancing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Role of AI in measuring social distancing / monitoring devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = cv2.imread('men.jpg')\n",
    "cv2.imshow('w1',men)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('face.xml')\n",
    "\n",
    "img = cv2.imread('men.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[377, 139]\n",
      "[85, 27]\n",
      "[474, 55]\n",
      "[[377, 139], [85, 27], [474, 55]]\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "lf=[]\n",
    "i=1\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    s=str(i)    # Face No.\n",
    "    cv2.putText(img, s, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0),2)   \n",
    " \n",
    "    # Putting text in the detected faces\n",
    "    i+=1\n",
    "    l=[]\n",
    "    l.append(x)\n",
    "    l.append(y)\n",
    "    lf.append(l)  \n",
    "\n",
    "    print(l)\n",
    "\n",
    "print(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312.74270575027003\n",
      "128.3160161476345\n",
      "390.00641020372984\n",
      "Person1and person3;are not following social distancing\n"
     ]
    }
   ],
   "source": [
    "close_person = \"\"\n",
    "import math\n",
    "for i in range(len(lf)):\n",
    "    for j in range(i+1, len(lf)):\n",
    "        d = math.sqrt((((lf[j][1] - lf[i][1])**2) + ((lf[j][0] - lf[i][0])**2)))\n",
    "        print(d)\n",
    "    if d<300:\n",
    "        close_person = close_person +  \"Person\" + str(i+1) + 'and person' + str(j+1) + \";\"\n",
    "close_person += \"are not following social distancing\"\n",
    "print(close_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Face Distance',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://goeduhub.com/40/opencv-with-live-webcam-images-and-videos?show=40#q40-\n",
    "\n",
    "http://goeduhub.com/9946/face-detection-in-an-image-using-opencv?show=9946#q9946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
